{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Levenshtein import ratio\n",
    "import eng_to_ipa\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load/create dictionary to translate identifiers from English to IPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ipa_translation_dict.json\n"
     ]
    }
   ],
   "source": [
    "# check for existing translation dictionary\n",
    "try:\n",
    "    dict_file = open('data/ipa_translation_dict.json', 'r')\n",
    "    dict = dict_file.read()\n",
    "    dict_file.close()\n",
    "\n",
    "    translate = json.loads(dict)\n",
    "\n",
    "    print('Loaded ipa_translation_dict.json')\n",
    "\n",
    "# if pre-translated dictionary is missing\n",
    "except FileNotFoundError:\n",
    "\n",
    "    id_freq = pd.read_csv('identifier_frequency.csv')\n",
    "    top_ids = id_freq['identifier'].astype(str)\n",
    "\n",
    "    translate = {}\n",
    "\n",
    "    for id in tqdm(top_ids):\n",
    "\n",
    "        parts = id.split('_')\n",
    "\n",
    "        for part in parts:\n",
    "            try:\n",
    "                translate[part]\n",
    "            except KeyError:\n",
    "                id_ipa = eng_to_ipa.convert(part)\n",
    "\n",
    "                # if 'id' is not translatable, convert returns 'id*'\n",
    "                # filter these out\n",
    "                if part not in id_ipa:\n",
    "                    translate[part] = id_ipa\n",
    "    \n",
    "    percent = str(np.round(100*len(translate)/len(top_ids)))\n",
    "    print(str(len(translate)) + ' identifiers are translatable (' + percent + '%)')\n",
    "\n",
    "    f = open('data/ipa_translation_dict.json', 'w')\n",
    "    f.write(json.dumps(translate))\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find similarity of every pair of identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5821/5821 [02:19<00:00, 41.64it/s] \n"
     ]
    }
   ],
   "source": [
    "words = list(translate)\n",
    "size = len(words)\n",
    "\n",
    "ipa_sim = np.zeros((size, size), dtype=np.uint8)\n",
    "eng_sim = np.zeros((size, size), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(size)):\n",
    "    for j in range(size):\n",
    "        \n",
    "        if i < j: # only compare each pair once\n",
    "\n",
    "            ipa_sim[i, j] = np.round(100*ratio(translate[words[i]], translate[words[j]]), 2)\n",
    "            eng_sim[i, j] = np.round(100*ratio(words[i], words[j]), 2)\n",
    "\n",
    "# get indices from largest to smallest similarity\n",
    "sorted = np.flip(np.argsort(ipa_sim.flatten()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save most similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33884041/33884041 [01:46<00:00, 317866.38it/s]\n"
     ]
    }
   ],
   "source": [
    "f = open('data/phonological_similarity.csv', 'w')\n",
    "\n",
    "f.write('word_1,word_2,IPA_similarity,english_similarity\\n')\n",
    "\n",
    "for n in tqdm(range(5821**2)):\n",
    "    i, j = np.unravel_index(sorted[n], (size, size))\n",
    "    if words[i] not in words[j] and words[j] not in words[i]:\n",
    "        f.write(words[i] + ',' + words[j] + ',' + str(ipa_sim[i, j])\n",
    "                + ',' + str(eng_sim[i, j]) + '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.read_csv('data/phonological_similarity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36893/2190371632.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  selected_ids = pd.DataFrame(sim_df[sim_df['english_similarity'] < 35][sim_df['IPA_similarity'] > 70])\n"
     ]
    }
   ],
   "source": [
    "selected_ids = pd.DataFrame(sim_df[sim_df['english_similarity'] < 35][sim_df['IPA_similarity'] > 70])\n",
    "\n",
    "selected_ids.reset_index(inplace=True, drop=True)\n",
    "selected_ids.to_csv('data/lex_diff_homophones.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ˈpɪkəl\n"
     ]
    }
   ],
   "source": [
    "print(eng_to_ipa.convert('pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ˈpɪksəl\n"
     ]
    }
   ],
   "source": [
    "print(eng_to_ipa.convert('pixel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones = [('label', 'table'),\n",
    "              ('new', 'nu'),\n",
    "              ('rho', 'row'),\n",
    "              ('picker', 'picture'), \n",
    "              ('pickle', 'pixel'),\n",
    "              ('x', 'checks'),\n",
    "              ('err', 'pair'),\n",
    "              ('queue', 'skew'),\n",
    "              ('y', 'i')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    table       0.6   0.86\n",
      "new      nu          0.4    1.0\n",
      "rho      row        0.67    1.0\n",
      "picker   picture    0.62   0.92\n",
      "pickle   pixel      0.55   0.92\n",
      "x        checks      0.0   0.86\n",
      "yerr     xypair      0.4    0.5\n",
      "queue    skew       0.22   0.86\n",
      "y        i           0.0    0.8\n"
     ]
    }
   ],
   "source": [
    "for w1, w2 in homophones:\n",
    "    eng = ratio(w1, w2)\n",
    "    ipa = ratio(eng_to_ipa.convert(w1), eng_to_ipa.convert(w2))\n",
    "    print(f'{w1:{8}} {w2:{8}} {eng:{6}.{2}} {ipa:{6}.{2}}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
